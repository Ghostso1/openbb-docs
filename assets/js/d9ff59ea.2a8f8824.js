"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[61306],{70658:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>o,default:()=>m,frontMatter:()=>l,metadata:()=>r,toc:()=>c});var s=n(74848),i=n(28453),a=n(94331);const l={title:"Forecast",description:"A comprehensive guide exploring the Forecast menu, a machine learning toolkit providing high-level, state-of-the-art, components. toolkit providing high-level components for quickly providing state-of-the-art results. Features include Data Loading, Data Exploration, Feature Engineering, Time Series Forecasting, Anomaly Detection, and Miscellaneous AI Tools. This page presents real-world examples and workflows for beginners and advanced users.",keywords:["Docusaurus","Metadata","Search Engine Optimization","Marketing","Web page","Content","Forecast menu","Machine learning toolkit","Time Series Forecasting","Anomaly Detection","Feature Engineering","Data Exploration","Data Loading","Dataset","AI Tools","Whisper","YouTube"]},o=void 0,r={id:"terminal/menus/forecast",title:"Forecast",description:"A comprehensive guide exploring the Forecast menu, a machine learning toolkit providing high-level, state-of-the-art, components. toolkit providing high-level components for quickly providing state-of-the-art results. Features include Data Loading, Data Exploration, Feature Engineering, Time Series Forecasting, Anomaly Detection, and Miscellaneous AI Tools. This page presents real-world examples and workflows for beginners and advanced users.",source:"@site/content/terminal/menus/forecast.md",sourceDirName:"terminal/menus",slug:"/terminal/menus/forecast",permalink:"/terminal/menus/forecast",draft:!1,unlisted:!1,editUrl:"https://github.com/OpenBB-finance/openbb-docs/edit/main/content/terminal/menus/forecast.md",tags:[],version:"current",lastUpdatedBy:"montezdesousa",lastUpdatedAt:1719240743e3,frontMatter:{title:"Forecast",description:"A comprehensive guide exploring the Forecast menu, a machine learning toolkit providing high-level, state-of-the-art, components. toolkit providing high-level components for quickly providing state-of-the-art results. Features include Data Loading, Data Exploration, Feature Engineering, Time Series Forecasting, Anomaly Detection, and Miscellaneous AI Tools. This page presents real-world examples and workflows for beginners and advanced users.",keywords:["Docusaurus","Metadata","Search Engine Optimization","Marketing","Web page","Content","Forecast menu","Machine learning toolkit","Time Series Forecasting","Anomaly Detection","Feature Engineering","Data Exploration","Data Loading","Dataset","AI Tools","Whisper","YouTube"]},sidebar:"tutorialSidebar",previous:{title:"Fixed Income",permalink:"/terminal/menus/fixedincome"},next:{title:"Forex",permalink:"/terminal/menus/forex"}},d={},c=[{value:"Usage",id:"usage",level:2},{value:"Loading Data",id:"loading-data",level:3},{value:"With the Load Command",id:"with-the-load-command",level:4},{value:"Via the Stocks/Crypto Menus",id:"via-the-stockscrypto-menus",level:4},{value:"Exploration",id:"exploration",level:3},{value:"Combine",id:"combine",level:4},{value:"Delete",id:"delete",level:4},{value:"Show",id:"show",level:4},{value:"Export",id:"export",level:4},{value:"Feature Engineering",id:"feature-engineering",level:3},{value:"Time Series Forecasting",id:"time-series-forecasting",level:3},{value:"Quantile Anomaly Detection",id:"quantile-anomaly-detection",level:3},{value:"Miscellaneous AI Tools",id:"miscellaneous-ai-tools",level:3},{value:"Whisper",id:"whisper",level:4},{value:"Sample Workflow #1 (Beginner)",id:"sample-workflow-1-beginner",level:2},{value:"plot",id:"plot",level:3},{value:"desc",id:"desc",level:3},{value:"expo",id:"expo",level:3},{value:"rnn",id:"rnn",level:3},{value:"Sample Workflow #2 (Advanced)",id:"sample-workflow-2-advanced",level:2},{value:"brnn",id:"brnn",level:3},{value:"regr",id:"regr",level:3}];function h(e){const t={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(a.A,{title:"Forecast - Menus | OpenBB Terminal Docs"}),"\n",(0,s.jsx)(t.p,{children:"The Forecast menu is a machine learning toolkit that provides practitioners with high-level, state-of-the-art, components.  Classical or deep learning models can be combined with low-level components and fine tuned to build new approaches and custom tuned models.  Bring in multiple datasets and train machine learning models with unlimited external factors to see how underlying data may change future forecasting predictions and accuracy."}),"\n",(0,s.jsx)(t.h2,{id:"usage",children:"Usage"}),"\n",(0,s.jsxs)(t.p,{children:["The Forecast menu is entered from the Main menu, ",(0,s.jsx)(t.code,{children:"forecast"}),", or with the absolute path:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:" /forecast\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233540050-071524c6-f374-4241-aa31-cf33b7685e22.png",alt:"The Forecast Menu"})}),"\n",(0,s.jsxs)(t.p,{children:["There are also methods for entering the menu with a loaded ticker symbol from either of the ",(0,s.jsxs)(t.a,{href:"/terminal/menus/crypto",children:[(0,s.jsx)(t.code,{children:"/crypto"})," menu"]})," and ",(0,s.jsxs)(t.a,{href:"/terminal/menus/stock",children:[(0,s.jsx)(t.code,{children:"/stocks"})," menu"]})]}),"\n",(0,s.jsx)(t.p,{children:"The menu is divided into sections for:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Loading Data"}),"\n",(0,s.jsx)(t.li,{children:"Data Exploration"}),"\n",(0,s.jsx)(t.li,{children:"Feature Engineering"}),"\n",(0,s.jsx)(t.li,{children:"Time Series Forecasting"}),"\n",(0,s.jsx)(t.li,{children:"Anomaly Detection"}),"\n",(0,s.jsx)(t.li,{children:"Miscellaneous AI Tools"}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"and the functions within these groups are described in the following sections."}),"\n",(0,s.jsx)(t.h3,{id:"loading-data",children:"Loading Data"}),"\n",(0,s.jsx)(t.h4,{id:"with-the-load-command",children:"With the Load Command"}),"\n",(0,s.jsxs)(t.p,{children:["If the Forecast menu has not been entered directly through the ",(0,s.jsx)(t.a,{href:"/website/content/terminal/menus/crypto",children:(0,s.jsx)(t.code,{children:"/crypto"})})," or ",(0,s.jsx)(t.a,{href:"/website/content/terminal/menus/stocks",children:(0,s.jsx)(t.code,{children:"/stocks"})})," menus, a dataset must be loaded before commencing any work.  Use the ",(0,s.jsx)(t.code,{children:"load"})," command to open one from a CSV file placed in the OpenBBUserData folder.  The paths where the auto completion engine is looking for files is printed on the screen directly above the ",(0,s.jsx)(t.code,{children:"load"})," command, ",(0,s.jsx)(t.code,{children:"Looking for data in:"})]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233540104-2aad880e-c077-448a-9aff-9d2f18baf19e.png",alt:"Loading Data"})}),"\n",(0,s.jsxs)(t.p,{children:["Use the following syntax to load a file and name a dataset, substituting ",(0,s.jsx)(t.code,{children:"vix_daily"})," with the name of the file."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"\nload --file vix_daily.csv --alias vix\n"})}),"\n",(0,s.jsxs)(t.p,{children:["To refresh the screen, enter: ",(0,s.jsx)(t.code,{children:"?"})]}),"\n",(0,s.jsxs)(t.p,{children:["The dataset will be listed under the ",(0,s.jsx)(t.code,{children:"load"})," command and display the column names within it."]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233540197-0222d0a6-6f08-42e3-9072-a248eeec6f53.png",alt:"Loading From a File"})}),"\n",(0,s.jsx)(t.p,{children:"Repeat the process until all desired datasets have been loaded."}),"\n",(0,s.jsx)(t.h4,{id:"via-the-stockscrypto-menus",children:"Via the Stocks/Crypto Menus"}),"\n",(0,s.jsxs)(t.p,{children:["Use the ",(0,s.jsx)(t.code,{children:"load"})," command, according to the nuances of each menu.  For example's sake, and to match the starting date of the previously loaded file, it will look like:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"/stocks/load SPY --start 1997-01-01/forecast\n"})}),"\n",(0,s.jsx)(t.p,{children:"Combine these two methods an unlimited number of times for building a more complex model and forecast."}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233540295-a7711fd8-992a-4561-b202-1b02a9a4aded.png",alt:"Load From Stocks Menu"})}),"\n",(0,s.jsx)(t.p,{children:"With some data loaded, the first series of tools are for inspecting, managing, and exporting the sets."}),"\n",(0,s.jsx)(t.h3,{id:"exploration",children:"Exploration"}),"\n",(0,s.jsx)(t.p,{children:"The exploration functions are listed in the table below, along with a short description."}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{style:{textAlign:"left"},children:"Function"}),(0,s.jsx)(t.th,{style:{textAlign:"right"},children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"clean"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Clean a dataset by filling or dropping NaNs."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"combine"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Combine columns from different datasets."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"corr"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Plot the correlation coefficients for dataset features."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"delete"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Delete columns from dataset."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"desc"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Show descriptive statistics of a dataset."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"export"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Export a processed dataset."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"plot"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Plot a specific columns of a loaded dataset."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"rename"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Rename columns from dataset."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"season"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Plot the seasonality for a dataset column."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"setndays"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Set the default number of days to forecast."})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"show"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Show a portion of a loaded dataset."})]})]})]}),"\n",(0,s.jsx)(t.h4,{id:"combine",children:"Combine"}),"\n",(0,s.jsxs)(t.p,{children:["When running a model, all targeted columns must be within the same dataset.  Use the ",(0,s.jsx)(t.code,{children:"combine"})," command to accomplish this by merging one column with another dataset."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"combine --dataset SPY -c vix.high\ncombine --dataset SPY -c vix.low\n"})}),"\n",(0,s.jsx)(t.p,{children:"The SPY time series now has two additional columns from the VIX dataframe, high and low."}),"\n",(0,s.jsx)(t.h4,{id:"delete",children:"Delete"}),"\n",(0,s.jsx)(t.p,{children:"It may be desirable to remove entire columns from the target dataset.  The syntax below removes the three columns from the SPY data loaded through the stocks menu."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"delete --delete SPY.adj_close\ndelete --delete SPY.stock_splits\ndelete --delete SPY.dividends\n"})}),"\n",(0,s.jsx)(t.h4,{id:"show",children:"Show"}),"\n",(0,s.jsxs)(t.p,{children:["After performing operations, examine the results using the ",(0,s.jsx)(t.code,{children:"show"})," command."]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233540348-e34d9342-f48e-48c1-ac0b-bef3261d8300.png",alt:"Show"})}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"show --name SPY\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233540386-eca474d6-596b-431e-9bf0-b7154257c877.png",alt:"Show Data"})}),"\n",(0,s.jsx)(t.h4,{id:"export",children:"Export"}),"\n",(0,s.jsx)(t.p,{children:"To save all of the combined changes within a dataset, export it to a new file."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"export -d SPY --type csv\n"})}),"\n",(0,s.jsxs)(t.p,{children:["This creates a new file in the ",(0,s.jsx)(t.a,{href:"/terminal/usage/data/custom-data",children:"OpenBBUserData folder"}),"."]}),"\n",(0,s.jsx)(t.h3,{id:"feature-engineering",children:"Feature Engineering"}),"\n",(0,s.jsx)(t.p,{children:"The Feature Engineering section provides methods for making fast calculations with a dataset.  Each one is listed below with a short description."}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{style:{textAlign:"left"},children:"Function"}),(0,s.jsx)(t.th,{style:{textAlign:"right"},children:"Description"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"atr"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Add Average True Range"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"delta"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Add % Change"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"ema"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Add Exponentially Weighted Moving Average"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"mom"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Add Momentum"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"roc"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Add Rate of Change"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"rsi"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Add Relative Strength Index"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"sto"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Add Stochastic Oscillator %K and %D"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"signal"}),(0,s.jsx)(t.td,{style:{textAlign:"right"},children:"Add Price Signal (short vs. long term)"})]})]})]}),"\n",(0,s.jsx)(t.p,{children:"Each function will have slight variations to the command syntax, but will generally operate similarly.  Print the help dialogue as a reminder."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"usage: rsi [-d {vix,SPY}] [-c TARGET_COLUMN] [--period PERIOD] [-h]\n\nAdd rsi to dataset based on specific column.\n\noptions:\n  -d {vix,SPY}, --dataset {vix,SPY}\n                        The name of the dataset you want to select (default: None)\n  -c TARGET_COLUMN, --target-column TARGET_COLUMN\n                        The name of the specific column you want to use (default: close)\n  --period PERIOD       The period to use (default: 10)\n  -h, --help            show this help message (default: False)\n\n\nFor more information and examples, use 'about rsi' to access the related guide.\n"})}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"\nusage: atr [--close-col CLOSE_COL] [--high-col HIGH_COL] [--low-col LOW_COL] [-d {vix,SPY}]\n           [-c TARGET_COLUMN] [-h]\n\nAdd Average True Range to dataset of specific stock ticker.\n\noptions:\n  --close-col CLOSE_COL\n                        Close column name to use for Average True Range. (default: close)\n  --high-col HIGH_COL   High column name to use for Average True Range. (default: high)\n  --low-col LOW_COL     Low column name to use for Average True Range. (default: low)\n  -d {vix,SPY}, --dataset {vix,SPY}\n                        The name of the dataset you want to select (default: None)\n  -c TARGET_COLUMN, --target-column TARGET_COLUMN\n                        The name of the specific column you want to use (default: close)\n  -h, --help            show this help message (default: False)\n\nFor more information and examples, use 'about atr' to access the related guide.\n"})}),"\n",(0,s.jsx)(t.p,{children:"To use these commands with the default settings, apply the syntax below."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"atr -d SPY\nrsi -d SPY\n"})}),"\n",(0,s.jsxs)(t.p,{children:["There are now two new columns in the SPY dataset, ",(0,s.jsx)(t.code,{children:"true_range, RSI_10_close"}),".  To keep the dataset organized, it may be worth  renaming these columns."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"rename -d SPY --oldcol RSI_10_close --newcol spy_rsi10\nrename -d SPY --oldcol true_range --newcol spy_atr\n"})}),"\n",(0,s.jsx)(t.h3,{id:"time-series-forecasting",children:"Time Series Forecasting"}),"\n",(0,s.jsxs)(t.p,{children:["This group of features applies models to a target dataset and its columns.  There are a wide selection to choose from.  Please note that this guide is meant explain how to use the functions and does not attempt to explain the models themselves.  This menu is an implementation of the ",(0,s.jsx)(t.a,{href:"https://unit8.com/resources/darts-time-series-made-easy-in-python/",children:"Unit8 Darts Time Series for Python"})," library."]}),"\n",(0,s.jsxs)(t.table,{children:[(0,s.jsx)(t.thead,{children:(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.th,{style:{textAlign:"left"},children:"Function"}),(0,s.jsx)(t.th,{style:{textAlign:"left"},children:"Description"}),(0,s.jsx)(t.th,{style:{textAlign:"left"},children:"Accepts Past Covariates?"})]})}),(0,s.jsxs)(t.tbody,{children:[(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"autoselect"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Select best statistical model from AutoARIMA, AutoETS, AutoCES, MSTL, etc."}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"No"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"autoarima"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Automatic ARIMA Model"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"No"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"autoces"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Automatic Complex Exponential Smoothing Model"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"No"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"autoets"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Automatic ETS (Error, Trend, Seasonality) Model"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"No"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"mstl"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Multiple Seasonalities and Trend using Loess (MSTL) Model"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"No"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"rwd"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Random Walk with Drift Model"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"No"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"seasonalnaive"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Seasonal Naive Model"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"No"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"expo"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Probabilistic Exponential Smoothing"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"No"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"theta"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Theta Method"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"No"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"linregr"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Probabilistic Linear Regression"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Yes"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"regr"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Regression"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Yes"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"brnn"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Block Recurrent Neural Network (RNN, LSTM, GRU)"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Yes"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"nbeats"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Neural Bayesian Estimation"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Yes"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"nhits"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Neural Hierarchical Interpolation"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Yes"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"tcn"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Temporal Convolutional Neural Network"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Yes"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"trans"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Transformer Network"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Yes"})]}),(0,s.jsxs)(t.tr,{children:[(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"tft"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Temporal Fusion Transformer Network"}),(0,s.jsx)(t.td,{style:{textAlign:"left"},children:"Yes"})]})]})]}),"\n",(0,s.jsx)(t.p,{children:"Within this list of models, there are two distinct categories:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Without past covariates."}),"\n",(0,s.jsx)(t.li,{children:"With past covariates."}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:["The models featuring past covariates will accept an unlimited number of columns, or all columns can be chosen.  The latter being more appropriate for when a dataset contains only columns which are deemed fit for the purpose.  To use any model in its default state, all that is required is the command name and the target dataset's name.  The default target column will always be ",(0,s.jsx)(t.code,{children:"close"})," so, a column must be defined to run a model if the target dataset does not contain a column with this name.  With the target column as ",(0,s.jsx)(t.code,{children:"close"}),", the basic default syntax will look like:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"rwd -d SPY\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233540491-34ba7cf0-dade-42d8-a165-5709ccf1e9fa.png",alt:"Random Walk Drift"})}),"\n",(0,s.jsx)(t.p,{children:"Each model should be reviewed carefully to understand what the adjustable parameters are, and how they should be defined."}),"\n",(0,s.jsx)(t.h3,{id:"quantile-anomaly-detection",children:"Quantile Anomaly Detection"}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.code,{children:"anom"})," performs a Quantile Anomaly detection on a given dataset.  Read more about this calculation ",(0,s.jsx)(t.a,{href:"https://unit8co.github.io/darts/generated_api/darts.ad.detectors.quantile_detector.html",children:"here"}),"."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"anom -d SPY\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233540548-1899cb39-35ef-4ea4-ac3c-1d1757f93ea8.png",alt:"Quantile Anomaly Detection"})}),"\n",(0,s.jsx)(t.h3,{id:"miscellaneous-ai-tools",children:"Miscellaneous AI Tools"}),"\n",(0,s.jsx)(t.h4,{id:"whisper",children:"Whisper"}),"\n",(0,s.jsxs)(t.p,{children:["The ",(0,s.jsx)(t.code,{children:"whisper"})," feature allows users to transcribe, translate, and summarize videos on YouTube.  These abilities empowers users to perform deeper research than ever before, and opens the door to a more complete view of the macroeconomic landscape.  The models are not installed until the first time it is used, and they can be quite significant in size.  Performance will vary, and there is currently not a method for offloading processing to dedicated GPUs."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:'whisper https://www.youtube.com/watch?v=G0Q0BtGQzrA\n\n[DISCLAIMER]: This is a beta feature that uses standard NLP models. More recent models such as GPT will be added in future releases.\n\nDownloading and Loading NLP Pipelines from cache...\n\nAll NLP Pipelines loaded.\n\nTranscribing and summarizing...\nDownloaded video "China stuck in 8 trillion dollar debt crisis | GyanJaraHatke with Sourabh Maheshwari". Generating subtitles...\nDetected language: Hindi\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 83567/83567 [04:25<00:00, 314.21frames/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 11/11 [02:44<00:00, 14.99s/it]\n\n-------------------------\nSummary: Reduction: 81.38%\nSentiment: NEGATIVE: 73.2596\n-------------------------\nChina is the largest economy in the world. Usually China\'s economy is seen in the global level of the economy of America...\n'})}),"\n",(0,s.jsx)(t.p,{children:"A file with the transcript is saved to the OpenBBUserData folder."}),"\n",(0,s.jsx)(t.h2,{id:"sample-workflow-1-beginner",children:"Sample Workflow #1 (Beginner)"}),"\n",(0,s.jsxs)(t.p,{children:["Let's begin by using one of the datasets we loaded in previously : ",(0,s.jsx)(t.code,{children:"SPY"})]}),"\n",(0,s.jsxs)(t.p,{children:["We will be forecasting ",(0,s.jsx)(t.code,{children:"5 Business days"})," ahead for the remaider of these workflows unless specified."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Note:"})," All models automatically perform Historical backtesting on the test split before providing a prediction."]}),"\n",(0,s.jsxs)(t.p,{children:["We use ",(0,s.jsx)(t.a,{href:"https://en.wikipedia.org/wiki/Mean_absolute_percentage_error",children:"MAPE"})," for the default as it is quite convenient and scale independent since it calculates error as a percentage instead of an absolute value.  There are many more metrics to compare time series.  The metrics will compare only common slices of series when the two series are not aligned, and parallelize computation over a large number of pairs of series. Additional metrics to choose from are RMSE, MSE, and SMAPE."]}),"\n",(0,s.jsx)(t.h3,{id:"plot",children:"plot"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"plot SPY.close\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233540628-cc0b58e6-6259-4893-9dfe-4fb73217a181.png",alt:"Plot"})}),"\n",(0,s.jsx)(t.h3,{id:"desc",children:"desc"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"desc SPY\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233540670-3d4df645-8fff-41a6-a4f7-0a1005dbdb11.png",alt:"Describe"})}),"\n",(0,s.jsx)(t.h3,{id:"expo",children:"expo"}),"\n",(0,s.jsxs)(t.p,{children:["Let's use a simple ",(0,s.jsx)(t.strong,{children:"Probabilistic Exponential Smoothing Model"})," to predict the close price.  Keep in mind all models are performing automatic historical backtesting before providing future forecasts.  Note that all models forecast ",(0,s.jsx)(t.code,{children:"close"})," by default."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"expo SPY\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233540707-1d87add0-b398-4083-9185-978e8e0bfe8c.png",alt:"Probalistic Exponential Smoothing Model"})}),"\n",(0,s.jsx)(t.h3,{id:"rnn",children:"rnn"}),"\n",(0,s.jsxs)(t.p,{children:["We can also play with some models that are bit more advanced. As we go down the list, models begin to become larger in parameter size and complexity.  This will play a key role later on when we want to train models with ",(0,s.jsx)(t.code,{children:"past_covariates"})," (aka. external factors)."]}),"\n",(0,s.jsxs)(t.p,{children:["This time lets test with a ",(0,s.jsx)(t.strong,{children:"Recurrent Neural Network"})," which by default uses an ",(0,s.jsx)(t.code,{children:"LSTM"})," backbone.  We can also choose to test out a ",(0,s.jsx)(t.code,{children:"GRU"})," backbone to experiment. Let's do both and see if we can improve our accuracy and reduce the overall MAPE."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"rnn SPY --forecast-only\n\nEpoch 50: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 214/214 [00:02<00:00, 77.77it/s, loss=-4.31, v_num=logs, train_loss=-4.46, val_loss=-.985]\n\nRNN model obtains MAPE: 3.13%\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233540770-28abd8d5-c301-4d26-bd88-77287a6d71d7.png",alt:"RNN"})}),"\n",(0,s.jsx)(t.p,{children:"This result expresses a different view from the Probabilistic Exponential Smoothing Model."}),"\n",(0,s.jsxs)(t.p,{children:["For the second task, we would like to change the model type from ",(0,s.jsx)(t.code,{children:"LSTM"})," --\x3e ",(0,s.jsx)(t.code,{children:"GRU"}),". Let's find out of this improves the MAPE score.  Use the ",(0,s.jsx)(t.code,{children:"-h"})," flag to understand the particular parameters one can change for RNN. (Please note that the parameters are different for each model)."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:'rnn -h\n\nusage: rnn [--hidden-dim HIDDEN_DIM] [--training_length TRAINING_LENGTH] [--naive] [-d {vix,SPY}] [-c TARGET_COLUMN] [-n N_DAYS]\n           [-t TRAIN_SPLIT] [-i INPUT_CHUNK_LENGTH] [--force-reset FORCE_RESET] [--save-checkpoints SAVE_CHECKPOINTS]\n           [--model-save-name MODEL_SAVE_NAME] [--n-epochs N_EPOCHS] [--model-type MODEL_TYPE] [--dropout DROPOUT] [--batch-size BATCH_SIZE]\n           [--end S_END_DATE] [--start S_START_DATE] [--learning-rate LEARNING_RATE] [--residuals] [--forecast-only] [--export-pred-raw]\n           [--metric {rmse,mse,mape,smape}] [-h] [--export EXPORT]\n\nPerform RNN forecast (Vanilla RNN, LSTM, GRU): https://unit8co.github.io/darts/generated_api/darts.models.forecasting.rnn_model.html\n\noptions:\n  --hidden-dim HIDDEN_DIM\n                        Size for feature maps for each hidden RNN layer (h_n) (default: 20)\n  --training_length TRAINING_LENGTH\n                        The length of both input (target and covariates) and output (target) time series used during training. Generally\n                        speaking, training_length should have a higher value than input_chunk_length because otherwise during training the RNN\n                        is never run for as many iterations as it will during training. (default: 20)\n  --naive               Show the naive baseline for a model. (default: False)\n  -d {vix,SPY}, --dataset {vix,SPY}\n                        The name of the dataset you want to select (default: None)\n  -c TARGET_COLUMN, --target-column TARGET_COLUMN\n                        The name of the specific column you want to use (default: close)\n  -n N_DAYS, --n-days N_DAYS\n                        prediction days. (default: 5)\n  -t TRAIN_SPLIT, --train-split TRAIN_SPLIT\n                        Start point for rolling training and forecast window. 0.0-1.0 (default: 0.85)\n  -i INPUT_CHUNK_LENGTH, --input-chunk-length INPUT_CHUNK_LENGTH\n                        Number of past time steps for forecasting module at prediction time. (default: 14)\n  --force-reset FORCE_RESET\n                        If set to True, any previously-existing model with the same name will be reset (all checkpoints will be discarded).\n                        (default: True)\n  --save-checkpoints SAVE_CHECKPOINTS\n                        Whether to automatically save the untrained model and checkpoints. (default: True)\n  --model-save-name MODEL_SAVE_NAME\n                        Name of the model to save. (default: rnn_model)\n  --n-epochs N_EPOCHS   Number of epochs over which to train the model. (default: 300)\n  --model-type MODEL_TYPE\n                        Enter a string specifying the RNN module type ("RNN", "LSTM" or "GRU") (default: LSTM)\n  --dropout DROPOUT     Fraction of neurons affected by Dropout, from 0 to 1. (default: 0)\n  --batch-size BATCH_SIZE\n                        Number of time series (input and output) used in each training pass (default: 32)\n  --end S_END_DATE      The end date (format YYYY-MM-DD) to select for testing (default: None)\n  --start S_START_DATE  The start date (format YYYY-MM-DD) to select for testing (default: None)\n  --learning-rate LEARNING_RATE\n                        Learning rate during training. (default: 0.001)\n  --residuals           Show the residuals for the model. (default: False)\n  --forecast-only       Do not plot the historical data without forecasts. (default: False)\n  --export-pred-raw     Export predictions to a csv file. (default: False)\n  --metric {rmse,mse,mape,smape}\n                        Calculate precision based on a specific metric (rmse, mse, mape) (default: mape)\n  -h, --help            show this help message (default: False)\n  --export EXPORT       Export figure into png, jpg, pdf, svg (default: )\n\nFor more information and examples, use \'about rnn\' to access the related guide.\n'})}),"\n",(0,s.jsxs)(t.p,{children:["Lets change the ",(0,s.jsx)(t.code,{children:"--model-type"})," parameter to ",(0,s.jsx)(t.code,{children:"GRU"})," and rerun."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"rnn SPY --model-type GRU --forecast-only\n\nEpoch 85: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 214/214 [00:02<00:00, 75.10it/s, loss=-4.45, v_num=logs, train_loss=-4.35, val_loss=-2.35]\n\nRNN model obtains MAPE: 2.77%\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233540843-2167a3ad-0088-4d84-a298-7b8b3b3655ff.png",alt:"RNN with GRU"})}),"\n",(0,s.jsx)(t.p,{children:"We improved the accuracy score, great work!"}),"\n",(0,s.jsx)(t.admonition,{type:"note",children:(0,s.jsxs)(t.p,{children:["The take away for this is that all models should work out of the box when forecasting for a particular time series. One can switch the target by specifying a ",(0,s.jsx)(t.code,{children:"-c"})," for ",(0,s.jsx)(t.code,{children:"TARGET_COLUMN"})," and test out performance with multiple different models with a single command."]})}),"\n",(0,s.jsx)(t.h2,{id:"sample-workflow-2-advanced",children:"Sample Workflow #2 (Advanced)"}),"\n",(0,s.jsx)(t.p,{children:"To build successful models and improve accuracy over time, it is important to capture external data related to the time series you are training on. This can be seen in everyday applications:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Observed rainfalls and known weather forecasts can help to predict hydro and solar electricity production"}),"\n",(0,s.jsx)(t.li,{children:"Recently-observed activity on an e-commerce website can help predict future sales."}),"\n",(0,s.jsx)(t.li,{children:"Making the model aware of up-coming holidays can help sales forecasting."}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"In fact, more often than not, strictly relying on the history of a time series\nto predict its future is missing a lot of valuable information."}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Past covariates"})," are time series whose past values are known at prediction\ntime. Those series often contain values that have to be observed to be known."]}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/105685594/190244764-ce8cf01f-c959-4827-a326-62b0e172332d.png",alt:"image"})}),"\n",(0,s.jsxs)(t.p,{children:["To explore this topic more, please read the ",(0,s.jsx)(t.a,{href:"https://medium.com/unit8-machine-learning-publication/time-series-forecasting-using-past-and-future-external-data-with-darts-1f0539585993",children:"blog post"})," written by the authors of Darts."]}),"\n",(0,s.jsxs)(t.p,{children:["Note that only the following models can handle ",(0,s.jsx)(t.code,{children:"past_covariates"}),": ",(0,s.jsx)(t.code,{children:"BlockRNNModel"}),", ",(0,s.jsx)(t.code,{children:"NBEATSModel"}),", ",(0,s.jsx)(t.code,{children:"TCNModel"}),", ",(0,s.jsx)(t.code,{children:"TransformerModel"}),", ",(0,s.jsx)(t.code,{children:"RegressionModel"})," (incl. ",(0,s.jsx)(t.code,{children:"LinearRegressionModel"}),"), ",(0,s.jsx)(t.code,{children:"Temporal Fusion Transformer"})]}),"\n",(0,s.jsx)(t.p,{children:"Earlier on in the guide we managed to accomplish the following:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Load multiple datasets."}),"\n",(0,s.jsx)(t.li,{children:"Combine datasets."}),"\n",(0,s.jsx)(t.li,{children:"Rename columns."}),"\n",(0,s.jsx)(t.li,{children:"Delete columns."}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"We will continue this workflow by:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Adding some correlation analysis."}),"\n",(0,s.jsxs)(t.li,{children:["Train models with ",(0,s.jsx)(t.code,{children:"past_covariates"}),"."]}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:["For practice, let's start fresh and rebuild the same dataset.  The ",(0,s.jsx)(t.a,{href:"/terminal/usage/routines/introduction-to-routines",children:"OpenBB Routine Scripts"})," can make quick work out of this chore.  Copy the block below and create a new ",(0,s.jsx)(t.code,{children:".openbb"})," file, in ",(0,s.jsx)(t.code,{children:"~/OpenBBUserData/routines/"}),", to follow along."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"/stocks\nload SPY --start 1997-01-01\nforecast\n..\nload ^VIX --start 1997-01-01\nforecast\ncombine --dataset SPY -c ^VIX.high\ncombine --dataset SPY -c ^VIX.low\ndelete --delete SPY.adj_close\ndelete --delete SPY.stock_splits\ndelete --delete SPY.dividends\natr -d SPY\nrsi -d SPY\nrename -d SPY --oldcol RSI_10_close --newcol SPY_rsi10\nrename -d SPY --oldcol true_range --newcol SPY_atr\nshow SPY\n"})}),"\n",(0,s.jsxs)(t.p,{children:["Restart the Terminal to ensure that the routine file is found by the ",(0,s.jsx)(t.code,{children:"/exe"})," command, and then run it."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"exe --file forecast_demo.openbb\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233540963-b62b6f6b-a595-4cee-8ce9-8876024b3da8.png",alt:"Forecast Routine Demo"})}),"\n",(0,s.jsx)(t.h3,{id:"brnn",children:"brnn"}),"\n",(0,s.jsxs)(t.p,{children:["Now take the new dataset and train a simple ",(0,s.jsx)(t.code,{children:"Block RNN"})," model on SPY's ",(0,s.jsx)(t.code,{children:"close"})," price, and again using ",(0,s.jsx)(t.code,{children:"past_covariates"})," on a single column."]}),"\n",(0,s.jsx)(t.p,{children:"Without past covariates:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"brnn SPY --forecast-only\n"})}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"Epoch 196: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 214/214 [00:01<00:00, 107.42it/s, loss=-4.09, v_num=logs, train_loss=-4.07, val_loss=-1.53]\n\nBlock RNN model obtains MAPE: 3.25%\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233541019-7bc0545e-f2f1-4a6d-84a2-7e7ac1de9043.png",alt:"BRNN Without Covariates"})}),"\n",(0,s.jsx)(t.p,{children:"With covariates:"}),"\n",(0,s.jsx)(t.p,{children:"To use any covariates, there are two options:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["specify specific columns with ",(0,s.jsx)(t.code,{children:"--past-covariates"})]}),"\n",(0,s.jsxs)(t.li,{children:["specify all columns as past covariates except the one you are forecasting\n",(0,s.jsx)(t.code,{children:"--all-past-covariates"})]}),"\n"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"brnn SPY --forecast-only --past-covariates volume\n"})}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"Covariate #0: volume\nEpoch 86: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 214/214 [00:02<00:00, 74.77it/s, loss=-4, v_num=logs, train_loss=-4.19, val_loss=-1.53]\nBlock RNN model obtains MAPE: 4.69%\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233541054-552243aa-0509-47fd-8ac8-42c0b433095a.png",alt:"BRNN With Past Covariates"})}),"\n",(0,s.jsxs)(t.p,{children:["It is evident here that adding in the external variable of ",(0,s.jsx)(t.code,{children:"volume"})," negatively affected the accuracy."]}),"\n",(0,s.jsx)(t.p,{children:"Let's try adding a new column for the 200-day moving average."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"ema -d SPY --period 200/brnn -d SPY --past-covariates EMA_200\n"})}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"Successfully added 'EMA_200' to 'SPY' dataset\nCovariate #0: EMA_200\nEpoch 79: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 214/214 [00:02<00:00, 87.78it/s, loss=-3.81, v_num=logs, train_loss=-3.78, val_loss=-.435\nBlock RNN model obtains MAPE: 4.60%\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233541105-0f8dc802-e569-4ce2-b16a-0610e1cb99b7.png",alt:"BRNN With EMA200"})}),"\n",(0,s.jsx)(t.p,{children:"This isn't an improvement.  It's possible that there is too much noise in the data, so let's try shortening the length of time being used to train."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"\nbrnn -d SPY --past-covariates EMA_200 -t 0.95\n\nCovariate #0: EMA_200\nEpoch 87: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 215/215 [00:02<00:00, 82.81it/s, loss=-3.87, v_num=logs, train_loss=-4.29, val_loss=-1.59]\nBlock RNN model obtains MAPE: 3.38%\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233541148-707d2167-46ee-47b1-b6dc-ed56b239f32f.png",alt:"Parameter Adjustments"})}),"\n",(0,s.jsx)(t.p,{children:"Removing the 2020 volatility from the window of observation made a massive improvement to the forecast.  Now let's see add all the columns in the dataset as past covariates."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"brnn -d SPY --all-past-covariates -t 0.95\n\nCovariate #0: open\nCovariate #1: high\nCovariate #2: low\nCovariate #3: volume\nCovariate #4: ^VIX_high\nCovariate #5: ^VIX_low\nCovariate #6: SPY_atr\nCovariate #7: SPY_rsi10\nCovariate #8: EMA_200\nEpoch 39: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 215/215 [00:02<00:00, 83.50it/s, loss=-3.92, v_num=logs, train_loss=-4.03, val_loss=-2.14]\nBlock RNN model obtains MAPE: 3.57%\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233541177-7ddd64be-ec79-4aaf-b30f-41607a7b7f68.png",alt:"BRNN with All Past Covariates"})}),"\n",(0,s.jsx)(t.p,{children:"Adding all of the columns that were created doesn't improve the MAPE score, but it does narrow the range of forecasted prices.  Playing around like this shows how small changes can have a large impact on a forecast.  It is important to test many variables and parameters without getting too caught up overfitting any particular model.  Validate a thesis before dedicating a large amount of time into it."}),"\n",(0,s.jsx)(t.h3,{id:"regr",children:"regr"}),"\n",(0,s.jsxs)(t.p,{children:["Using the ",(0,s.jsx)(t.code,{children:"regr"})," function with ",(0,s.jsx)(t.code,{children:"all-past-covariates"})," on the same dataset gives dramatically different forecast."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"regr SPY --all-past-covariates\n\nCovariate #0: open\nCovariate #1: high\nCovariate #2: low\nCovariate #3: volume\nCovariate #4: ^VIX_high\nCovariate #5: ^VIX_low\nCovariate #6: SPY_atr\nCovariate #7: SPY_rsi10\nPredicting Regression for 5 days\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1026/1026 [00:48<00:00, 21.35it/s]\nRegression model obtains MAPE: 2.68%\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233541224-c2cbbaba-0b33-4d79-930a-dd2629d6ed94.png",alt:"regr"})}),"\n",(0,s.jsx)(t.p,{children:"Now that we know how to use covariates, and are starting to understand their effects, let's examine the impact of MSFT and AAPL closing prices on the regression forecast for SPY.  We will discard the previous work and start fresh."}),"\n",(0,s.jsx)(t.p,{children:"The cache can be purged by resetting the Terminal.  Use this command to clear it:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"/r\n"})}),"\n",(0,s.jsx)(t.p,{children:"Now we will fetch the data and combine the columns:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"/stocks/load spy\nforecast\n..\nload aapl\nforecast\n..\nload msft\nforecast\ndelete --delete SPY.stock_splits\ndelete --delete SPY.adj_close\ndelete --delete SPY.dividends\ncombine SPY -c AAPL.close\ncombine SPY -c MSFT.close\nregr SPY --forecast-only --past-covariates AAPL_close,MSFT_close\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsxs)(t.strong,{children:["Remember: You can use unlimited number of ",(0,s.jsx)(t.code,{children:"past_covariates"})," but they must all be combined into a single dataframe with the target forecast time series before training."]})}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"Covariate #0: AAPL_close\nCovariate #1: MSFT_close\nPredicting Regression for 5 days\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 115/115 [00:01<00:00, 96.07it/s]\nRegression model obtains MAPE: 1.77%\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233541267-42a541e2-ff5f-429e-a9fd-b9d2c76060ce.png",alt:"Regression with Past Covariates"})}),"\n",(0,s.jsx)(t.p,{children:"Adding the rest of the columns as past covariates improves the MAPE score slightly and starts to take a more directional view."}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-console",children:"regr --all-past-covariates -d SPY\n\nCovariate #0: open\nCovariate #1: high\nCovariate #2: low\nCovariate #3: volume\nCovariate #4: AAPL_close\nCovariate #5: MSFT_close\nPredicting Regression for 5 days\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 115/115 [00:00<00:00, 117.16it/s]\nRegression model obtains MAPE: 1.66%\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.img,{src:"https://user-images.githubusercontent.com/85772166/233541328-931117ff-9a84-437d-b8e8-b653d56335bc.png",alt:"Regression with All Past Covariates"})}),"\n",(0,s.jsx)(t.admonition,{type:"note",children:(0,s.jsxs)(t.p,{children:["The examples here are over-simplified as a means for demonstrating a framework to create and conduct experiments.  It is important to keep in mind that these are tools, they are not oracles, and that results may vary.  If you have any questions, requests for new feature engineering and model additions, or just want to be part of the conversation, please join us on ",(0,s.jsx)(t.a,{href:"openbb.co/discord",children:"Discord"}),".  Happy hacking!"]})})]})}function m(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},94331:(e,t,n)=>{n.d(t,{A:()=>a});n(96540);var s=n(5260),i=n(74848);function a(e){let{title:t}=e;return(0,i.jsx)(s.A,{children:(0,i.jsx)("title",{children:t})})}},28453:(e,t,n)=>{n.d(t,{R:()=>l,x:()=>o});var s=n(96540);const i={},a=s.createContext(i);function l(e){const t=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),s.createElement(a.Provider,{value:t},e.children)}}}]);